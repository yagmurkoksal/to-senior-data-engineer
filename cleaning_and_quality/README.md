This section includes a range of practical implementations focused on data cleaning and quality assurance â€” both of which are core components of any data engineering workflow. *Due to GitHub repository file size limitations, the actual datasets have not been uploaded to the repository.*

### Datasets

**Adult income dataset cleaning**

You can access the dataset from the following link: ðŸ”— [Dataset Link ](https://www.kaggle.com/datasets/wenruliu/adult-income-dataset)

**E-Commerce Data cleaning**

You can access the dataset from the following link: ðŸ”— [Dataset Link ](https://www.kaggle.com/datasets/carrie1/ecommerce-data)

**NYC Yellow Taxi Trip Data cleaning**

You can access the dataset from the following link: ðŸ”— [Dataset Link ](https://www.kaggle.com/datasets/elemento/nyc-yellow-taxi-trip-data?resource=download)

**Individual Household Electric Power Consumption dataset cleaning**

You can access the dataset from the following link: ðŸ”— [Dataset Link ](https://archive.ics.uci.edu/dataset/235/individual+household+electric+power+consumption)

**Covid-19 Twitter Dataset cleaning**

You can access the dataset from the following link: ðŸ”— [Dataset Link ](https://www.kaggle.com/datasets/arunavakrchakraborty/covid19-twitter-dataset)

### Usage 
This assumes you have completed the readme steps in the main project path (venv creation, requirements install)

- Download specified dataset and place under related path  (Example) 
    ```
    cleaning_and_quality/e_commerce/data
    ```
- Run script:
    ```
    python cleaning_and_quality/e_commerce/e_commerce_cleaning.py
    ```

- Check the output file:
    ```
    cleaning_and_quality/e_commerce/data/cleaned_ecommerce_data.csv
    ```

